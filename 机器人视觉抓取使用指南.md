# 机器人视觉抓取系统使用指南

## 目录
1. [项目概述](#项目概述)
2. [系统要求](#系统要求)
3. [安装步骤](#安装步骤)
4. [配置详解](#配置详解)
5. [使用步骤](#使用步骤)
6. [参数调优指南](#参数调优指南)
7. [故障排除](#故障排除)
8. [注意事项](#注意事项)

---

## 项目概述

本项目是一个基于**手眼标定（眼在手上）**的机器人视觉抓取系统，主要功能包括：

- **颜色物体检测**：实时检测视野中有颜色的正方体中心点
- **3D位姿估算**：计算物体在机器人基坐标系中的位置和姿态
- **机器人控制**：控制机器人移动到检测位置进行抓取操作

### 工作原理

1. **图像采集**：RealSense深度相机实时采集彩色图像和深度图像
2. **颜色检测**：在HSV颜色空间中检测指定颜色的物体，获取中心像素坐标
3. **坐标转换**：
   - 使用深度信息将2D像素坐标转换为3D相机坐标
   - 通过手眼标定矩阵将相机坐标转换为夹爪坐标
   - 结合机器人初始位姿转换为基坐标系坐标
4. **姿态计算**：可选地估算物体表面法向量，计算抓取姿态
5. **机器人控制**：将计算得到的位姿发送给机器人执行移动

---

## 系统要求

### 硬件要求
- **机器人**：支持RPC通信的工业机器人（如UR、KUKA等）
- **相机**：Intel RealSense深度相机（D435/D435i/D455等）
- **计算机**：Windows 10/11（推荐），或Linux系统
- **网络**：机器人与计算机在同一局域网内

### 软件要求
- Python 3.7 或更高版本
- Intel RealSense SDK 2.0（通常随pyrealsense2安装）
- 机器人控制库（Robot.py）

---

## 安装步骤

### 1. 克隆或下载项目

```bash
# 如果使用git
git clone <项目地址>
cd eyeInHand

# 或直接下载解压项目文件
```

### 2. 安装Python依赖

使用pip安装依赖包：

```bash
pip install -r requirements.txt
```

**依赖包说明**：
- `numpy>=1.20.0`：数值计算
- `opencv-python>=4.5.0`：图像处理
- `pyrealsense2>=2.50.0`：RealSense相机驱动
- `scipy>=1.7.0`：科学计算（旋转矩阵等）
- `Pillow>=8.0.0`：图像处理支持

**注意**：如果安装pyrealsense2遇到问题，可能需要先安装Intel RealSense SDK。

### 3. 连接硬件

1. **连接相机**：将RealSense相机通过USB 3.0接口连接到计算机
2. **连接机器人**：确保机器人与计算机在同一局域网，记录机器人IP地址
3. **测试连接**：
   - 相机：运行 `python -c "import pyrealsense2 as rs; print('相机驱动正常')"`
   - 机器人：确保可以通过IP地址ping通机器人

### 4. 准备标定文件

**重要**：在使用系统前，必须先完成手眼标定。标定文件应位于 `calibration/` 目录下。

如果还没有标定文件，请参考 `手眼标定使用指南.md` 进行标定。

---

## 配置详解

### 配置文件位置

项目有两个主要配置文件：
- `src/config/detection_config.py`：检测相关配置
- `src/config/robot_config.py`：机器人相关配置

### 1. 机器人配置 (`src/config/robot_config.py`)

#### DEFAULT_ROBOT_IP
```python
DEFAULT_ROBOT_IP = '192.168.2.68'
```
- **说明**：机器人的IP地址
- **如何设置**：修改为你的机器人实际IP地址
- **如何查找**：在机器人示教器上查看网络设置，或使用网络扫描工具

#### DEFAULT_ROBOT_TOOL
```python
DEFAULT_ROBOT_TOOL = 0
```
- **说明**：机器人工具号（TCP工具坐标系编号）
- **默认值**：0（通常表示默认工具）
- **如何设置**：根据你的机器人工具配置修改

#### DEFAULT_ROBOT_USER
```python
DEFAULT_ROBOT_USER = 0
```
- **说明**：机器人用户坐标系编号
- **默认值**：0（通常表示基坐标系）
- **如何设置**：如果使用自定义用户坐标系，修改为对应编号

#### KEY_DEBOUNCE_TIME
```python
KEY_DEBOUNCE_TIME = 0.0
```
- **说明**：按键防抖时间（秒），防止按键重复触发
- **默认值**：0.0（无防抖）
- **建议值**：通常保持0.0即可，如果出现按键重复触发，可设置为0.1-0.3

### 2. 检测配置 (`src/config/detection_config.py`)

#### CALIB_FILE
```python
CALIB_FILE = os.path.join(CALIBRATION_DIR, 'hand_eye_calibration_Horaud.npz')
```
- **说明**：手眼标定文件路径
- **如何选择**：
  - `hand_eye_calibration_Tsai.npz`：Tsai算法标定结果
  - `hand_eye_calibration_Park.npz`：Park算法标定结果
  - `hand_eye_calibration_Horaud.npz`：Horaud算法标定结果（推荐）
- **建议**：使用标定误差最小的算法对应的文件

#### ROBOT_INITIAL_POSE
```python
ROBOT_INITIAL_POSE = [-222.449, -285.088, 334.716, -180.0, 0.0, 90.0]
```
- **说明**：机器人拍照时的初始位姿 `[x, y, z, rx, ry, rz]`
  - `x, y, z`：位置（单位：mm）
  - `rx, ry, rz`：欧拉角（单位：度）
- **如何设置**：
  1. 手动控制机器人移动到拍照位置（相机视野覆盖工作区域）
  2. 记录当前TCP位姿
  3. 将位姿值填入此配置
- **注意事项**：
  - 此位姿必须与标定时的拍照位姿一致
  - 确保相机视野能覆盖需要检测的工作区域
  - 确保机器人不会与工作台或物体碰撞

#### TOOL_LENGTH
```python
TOOL_LENGTH = 235.0  # 单位：mm
```
- **说明**：工具/夹爪长度（从法兰到夹爪尖端的距离）
- **如何测量**：
  1. 测量机器人法兰盘到夹爪尖端的直线距离
  2. 如果使用TCP标定，TCP标定长度即为TOOL_LENGTH
- **典型值**：
  - 小型夹爪：100-150mm
  - 中型夹爪：200-250mm
  - 大型夹爪：300-400mm
- **影响**：此值直接影响最终抓取位置的Z坐标

#### Z_OFFSET
```python
Z_OFFSET = -10.0  # 单位：mm
```
- **说明**：夹爪末端沿法线方向的偏移量（最终目标位置的Z坐标偏移）
  - **负值**：表示夹爪末端在检测表面上方（悬停高度）
  - **正值**：表示夹爪末端在检测表面下方（会穿透表面）
- **作用**：设置最终抓取位置相对于检测表面的高度，避免机器人直接碰撞物体
- **如何设置**：
  - **初始值**：建议从 `-10.0` 开始
  - **调整方法**：
    - 如果抓取时碰撞物体：减小绝对值（如改为 `-5.0`）
    - 如果抓取不到物体：增大绝对值（如改为 `-20.0`）
  - **安全范围**：通常设置在 `-5.0` 到 `-30.0` 之间
- **注意事项**：
  - 此值需要根据实际抓取工艺调整
  - 如果物体较厚，可能需要更大的负值
  - 如果物体较薄或需要精确抓取，使用较小的负值
  - **与HOVER_HEIGHT的区别**：Z_OFFSET是最终目标位置的偏移，HOVER_HEIGHT是第一阶段悬停位置的偏移

#### HOVER_HEIGHT
```python
HOVER_HEIGHT = 50.0  # 单位：mm
```
- **说明**：两阶段运动时，第一阶段悬停位置的z坐标相对于目标z坐标的偏移量
  - **正值**：表示悬停位置在目标位置上方（推荐）
  - **负值**：表示悬停位置在目标位置下方（不推荐）
- **作用**：控制两阶段运动的第一阶段，使机器人先移动到目标位置上方悬停，再下降到目标位置，提高安全性
- **如何设置**：
  - **初始值**：建议从 `50.0` 开始
  - **调整方法**：
    - 如果工作空间较小：减小此值（如改为 `30.0`）
    - 如果需要更高的安全性：增大此值（如改为 `80.0`）
  - **安全范围**：通常设置在 `30.0` 到 `100.0` 之间
- **两阶段运动流程**：
  1. **第一阶段**：机器人移动到悬停位置（x, y, rx, ry, rz保持不变，z = 目标z + HOVER_HEIGHT）
  2. **第二阶段**：机器人从悬停位置下降到目标位置（完整的目标位姿）
- **注意事项**：
  - 此值需要确保悬停位置在机器人工作空间内
  - 如果悬停位置过高，可能导致机器人无法到达
  - 如果悬停位置过低，可能失去两阶段运动的安全优势
  - 建议根据实际工作空间和物体高度调整

#### X_OFFSET 和 Y_OFFSET
```python
X_OFFSET = -12.0  # 单位：mm
Y_OFFSET = 5.0    # 单位：mm
```
- **说明**：X、Y轴方向的系统误差补偿
- **作用**：补偿标定误差或相机安装偏差导致的系统性偏移
- **如何设置**：
  1. **初始值**：都设置为 `0.0`
  2. **测试抓取**：运行系统，检测物体并控制机器人抓取
  3. **观察偏差**：
     - 如果实际抓取位置在X方向偏右（机器人坐标系），设置 `X_OFFSET` 为负值
     - 如果实际抓取位置在X方向偏左，设置 `X_OFFSET` 为正值
     - Y方向同理
  4. **调整方法**：
     - 偏差10mm，设置对应OFFSET为 `-10.0` 或 `10.0`
     - 多次测试，逐步调整到最佳值
- **典型范围**：`-20.0` 到 `20.0` 之间

#### COLOR_RANGES（颜色阈值配置）

```python
COLOR_RANGES = {
    'blue': (np.array([100, 120, 70]), np.array([130, 255, 255])),
    'red1': (np.array([0, 120, 70]), np.array([10, 255, 255])),
    'red2': (np.array([170, 120, 70]), np.array([180, 255, 255])),
    'green': (np.array([40, 60, 70]), np.array([85, 255, 255])),
    'yellow': (np.array([22, 120, 120]), np.array([35, 255, 255])),
    'orange': (np.array([10, 120, 120]), np.array([22, 255, 255])),
    'purple': (np.array([135, 60, 70]), np.array([165, 255, 255])),
}
```

- **说明**：HSV颜色空间的阈值范围，用于检测不同颜色的物体
- **格式**：`(lower_bound, upper_bound)`，每个bound是 `[H, S, V]` 数组
  - **H（色相）**：0-180（OpenCV中H范围是0-180）
  - **S（饱和度）**：0-255
  - **V（明度）**：0-255
- **如何调整颜色阈值**：

  **方法1：使用OpenCV颜色选择器**
  ```python
  import cv2
  import numpy as np
  
  def nothing(x):
      pass
  
  cv2.namedWindow('Trackbar')
  cv2.createTrackbar('H Min', 'Trackbar', 0, 180, nothing)
  cv2.createTrackbar('H Max', 'Trackbar', 180, 180, nothing)
  cv2.createTrackbar('S Min', 'Trackbar', 0, 255, nothing)
  cv2.createTrackbar('S Max', 'Trackbar', 255, 255, nothing)
  cv2.createTrackbar('V Min', 'Trackbar', 0, 255, nothing)
  cv2.createTrackbar('V Max', 'Trackbar', 255, 255, nothing)
  
  cap = cv2.VideoCapture(0)  # 或使用RealSense相机
  while True:
      ret, frame = cap.read()
      hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
      
      h_min = cv2.getTrackbarPos('H Min', 'Trackbar')
      h_max = cv2.getTrackbarPos('H Max', 'Trackbar')
      s_min = cv2.getTrackbarPos('S Min', 'Trackbar')
      s_max = cv2.getTrackbarPos('S Max', 'Trackbar')
      v_min = cv2.getTrackbarPos('V Min', 'Trackbar')
      v_max = cv2.getTrackbarPos('V Max', 'Trackbar')
      
      lower = np.array([h_min, s_min, v_min])
      upper = np.array([h_max, s_max, v_max])
      mask = cv2.inRange(hsv, lower, upper)
      result = cv2.bitwise_and(frame, frame, mask=mask)
      
      cv2.imshow('Original', frame)
      cv2.imshow('Mask', mask)
      cv2.imshow('Result', result)
      
      if cv2.waitKey(1) & 0xFF == ord('q'):
          break
      print(f"Lower: [{h_min}, {s_min}, {v_min}], Upper: [{h_max}, {s_max}, {v_max}]")
  ```

  **方法2：手动调整**
  - 如果检测不到物体：放宽阈值范围（减小S和V的最小值，增大H的范围）
  - 如果检测到背景：收紧阈值范围（增大S和V的最小值）
  - 红色需要两个范围：因为红色在HSV色环的两端（0附近和180附近）

- **常见颜色HSV范围参考**：
  - **蓝色**：H: 100-130
  - **绿色**：H: 40-85
  - **红色**：H: 0-10 或 170-180
  - **黄色**：H: 22-35
  - **橙色**：H: 10-22
  - **紫色**：H: 135-165

#### ENABLE_NORMAL_ESTIMATION
```python
ENABLE_NORMAL_ESTIMATION = True
```
- **说明**：是否启用法向量估算功能
- **True**：自动估算物体表面法向量，计算抓取姿态（适用于有明确表面的物体）
- **False**：使用固定姿态（ROBOT_INITIAL_POSE中的姿态）
- **如何选择**：
  - **启用**：物体有明确的平面表面（如正方体顶面），需要根据表面姿态调整抓取角度
  - **禁用**：物体形状不规则，或只需要垂直抓取
- **性能影响**：启用会增加计算量，但通常影响不大

#### NORMAL_NEIGHBORHOOD_SIZE
```python
NORMAL_NEIGHBORHOOD_SIZE = 15  # 单位：像素
```
- **说明**：法向量估算的邻域区域边长（像素）
- **作用**：在此区域内采样点云以估算表面法线
- **如何调整**：
  - **增大**（如20-30）：法向量更平滑，但对边缘不敏感
  - **减小**（如10）：对边缘更敏感，但可能受噪声影响
- **建议值**：15-20（适用于大多数情况）

#### MIN_POINTS_FOR_NORMAL
```python
MIN_POINTS_FOR_NORMAL = 10
```
- **说明**：计算法向量时需要的最小有效点数
- **作用**：如果邻域内有效点太少，认为法向估算不可靠
- **如何调整**：
  - 如果经常提示"深度无效"：减小此值（如5）
  - 如果法向量不稳定：增大此值（如15-20）
- **建议值**：10（适用于大多数情况）

#### DEPTH_FILTER_THRESHOLD
```python
DEPTH_FILTER_THRESHOLD = 0.01  # 单位：米
```
- **说明**：深度邻域采样点的有效性阈值
- **作用**：采样点深度与中心点深度相差超过此值不参与法线估算，过滤离群点
- **如何调整**：
  - 如果物体表面不平整：增大此值（如0.02-0.03）
  - 如果物体表面很平整：减小此值（如0.005）
- **建议值**：0.01（适用于大多数情况）

#### AXIS_SIGN
```python
AXIS_SIGN = [1, 1, 1]
```
- **说明**：坐标轴方向修正配置，用于调整输出的x, y, z三轴的符号
- **格式**：`[x_sign, y_sign, z_sign]`，每个值为1或-1
- **何时需要调整**：
  - 如果检测到的X坐标方向与实际相反：设置 `[x_sign, y_sign, z_sign]` 中x_sign为-1
  - Y、Z方向同理
- **如何确定**：
  1. 运行系统检测物体
  2. 观察输出的坐标方向
  3. 如果方向相反，修改对应轴的符号
- **默认值**：`[1, 1, 1]`（通常不需要修改）

#### DETECT_EULER_ORDER
```python
DETECT_EULER_ORDER = 'xyz'
```
- **说明**：欧拉角顺序定义，用于旋转矩阵与欧拉角的转换
- **选项**：`'xyz'`, `'xzy'`, `'yxz'`, `'yzx'`, `'zxy'`, `'zyx'`
- **如何选择**：必须与机器人使用的欧拉角顺序一致
  - UR机器人通常使用 `'xyz'`（先绕X轴，再Y轴，再Z轴）
  - 其他机器人可能不同，请查阅机器人文档
- **默认值**：`'xyz'`（适用于UR机器人）

#### SMOOTH_ALPHA_POS 和 SMOOTH_ALPHA_ROT
```python
SMOOTH_ALPHA_POS = 0.5  # 位置平滑系数
SMOOTH_ALPHA_ROT = 0.5  # 角度平滑系数
```
- **说明**：位姿平滑滤波系数（范围0.0-1.0）
- **作用**：平滑检测结果，减少抖动
- **注意**：当前版本已禁用平滑处理，这些参数暂时不起作用
- **如果启用平滑**：
  - **值越小**（如0.1-0.3）：更平滑，但延迟更高
  - **值越大**（如0.7-0.9）：响应更快，但可能抖动
  - **建议值**：0.3-0.5

---

## 使用步骤

### 第一步：准备工作

1. **检查硬件连接**
   - 确认RealSense相机已连接并正常工作
   - 确认机器人已上电并处于可控制状态
   - 确认机器人与计算机网络连通

2. **检查配置文件**
   - 打开 `src/config/robot_config.py`，确认 `DEFAULT_ROBOT_IP` 正确
   - 打开 `src/config/detection_config.py`，确认以下配置：
     - `CALIB_FILE`：标定文件路径正确
     - `ROBOT_INITIAL_POSE`：机器人初始位姿正确
     - `TOOL_LENGTH`：工具长度正确
     - `COLOR_RANGES`：颜色阈值适合你的物体

3. **准备测试物体**
   - 准备一个有颜色的正方体（颜色在COLOR_RANGES中已配置）
   - 将物体放置在相机视野内，确保：
     - 物体清晰可见
     - 光照充足且均匀
     - 背景与物体颜色对比明显

### 第二步：启动程序

1. **打开终端/命令行**
   ```bash
   cd d:\CPS\eyeInHand
   ```

2. **运行主程序**
   ```bash
   python robot_control.py
   ```

3. **观察启动信息**
   - 程序启动后会显示：
     - 机器人连接状态
     - 标定文件加载状态
     - 相机初始化状态
     - 当前模式（法向量估计模式/固定姿态模式）
     - TCP补偿长度、Z偏移量和悬浮高度
     - 快捷键说明

### 第三步：检测物体

1. **观察检测窗口**
   - 程序会打开一个名为"Detection"的窗口
   - 窗口显示实时相机画面
   - 如果检测到物体，会显示：
     - 绿色轮廓：检测到的物体轮廓
     - 红色圆点：物体中心点
     - 左上角：位置和姿态信息（X, Y, Z, Rx, Ry, Rz）
     - 右上角：操作提示

2. **调整物体位置**
   - 如果检测不到物体：
     - 检查物体颜色是否在COLOR_RANGES中
     - 调整光照条件
     - 调整物体位置，确保在相机视野内
     - 可能需要调整颜色阈值（参考[参数调优指南](#参数调优指南)）

3. **观察检测结果**
   - 左上角显示的位置和姿态会实时更新
   - 控制台会实时打印检测到的位姿坐标

### 第四步：保存检测坐标

1. **暂停检测**
   - 按键盘 **Q** 键暂停检测
   - 暂停时会自动保存当前检测到的物体坐标
   - 控制台会显示："已保存检测到的物体坐标: [x, y, z, rx, ry, rz]"
   - 窗口右上角会显示："已暂停 - 按Q恢复"

2. **确认保存的坐标**
   - 暂停后，窗口左上角会显示保存的坐标
   - 检查坐标是否合理：
     - X, Y, Z应该在机器人工作空间内
     - 如果坐标异常，按Q恢复，重新检测

3. **恢复检测**（可选）
   - 如果坐标不满意，按 **Q** 恢复检测
   - 调整物体位置后，再次按 **Q** 暂停保存

### 第五步：控制机器人移动

**重要安全提示**：
- 确保机器人工作空间内没有人员
- 确保物体位置安全，不会导致碰撞
- 随时准备按 **Z** 键停止机器人

#### 两阶段运动说明

系统采用**两阶段运动**策略，提高移动安全性：

1. **第一阶段：移动到悬停位置**
   - 机器人先移动到目标位置上方（x, y, rx, ry, rz保持不变）
   - Z坐标 = 目标Z坐标 + HOVER_HEIGHT（悬浮高度）
   - 例如：如果目标z=100mm，HOVER_HEIGHT=50mm，则悬停位置z=150mm

2. **第二阶段：下降到目标位置**
   - 机器人从悬停位置垂直下降到最终目标位置
   - 移动到完整的目标位姿（x, y, z, rx, ry, rz）

**优势**：
- 避免机器人在移动过程中碰撞物体或工作台
- 可以先观察悬停位置是否正确
- 如果发现问题，可以在悬停阶段停止机器人

#### 操作步骤

1. **启动两阶段移动**
   - 在暂停状态下，按键盘 **W** 键
   - 程序会控制机器人执行两阶段移动
   - 控制台会显示：
     - "第一阶段：移动到悬停位置 z=XXXmm"
     - "第一阶段完成：已到达悬停位置"
     - "第二阶段：下降到目标位置 z=XXXmm"
     - "第二阶段完成：已到达目标位置"
     - "两阶段运动完成"

2. **观察机器人移动**
   - 窗口左上角会显示："机器人正在移动中..."
   - **第一阶段**：观察机器人是否安全移动到悬停位置
   - **第二阶段**：观察机器人是否准确下降到目标位置
   - 如果发现异常，立即按 **Z** 键停止

3. **停止移动**（如需要）
   - 任何时候按 **Z** 键可以停止机器人移动
   - 可以在第一阶段或第二阶段停止
   - 控制台会显示："移动已被用户停止（第一阶段）"或"移动已被用户停止（第二阶段）"

4. **回到初始位姿**
   - 按键盘 **B** 键可以让机器人回到初始位姿（ROBOT_INITIAL_POSE）
   - 这是一个全局快捷键，可以在任何时候使用
   - 注意：回到初始位姿是单阶段移动，直接移动到目标位置

### 第六步：完成操作

1. **退出程序**
   - 按键盘 **ESC** 键退出程序
   - 程序会自动：
     - 停止相机
     - 关闭机器人连接
     - 关闭所有窗口

2. **检查结果**
   - 确认机器人已移动到正确位置
   - 如果位置不准确，参考[参数调优指南](#参数调优指南)进行调整

---

## 参数调优指南

### 调优流程

参数调优是一个迭代过程，建议按以下顺序进行：

1. **基础配置**（必须正确）
   - 机器人IP地址
   - 标定文件
   - 机器人初始位姿
   - 工具长度

2. **颜色检测**（确保能检测到物体）
   - 颜色阈值
   - 光照条件

3. **位置精度**（确保位置准确）
   - X_OFFSET 和 Y_OFFSET
   - Z_OFFSET

4. **姿态精度**（如果需要）
   - 法向量相关参数
   - 欧拉角顺序

### 调优方法

#### 1. 颜色检测调优

**问题**：检测不到物体

**解决方法**：
1. 检查物体颜色是否在COLOR_RANGES中
2. 使用OpenCV颜色选择器工具调整阈值（参考[COLOR_RANGES配置](#color_ranges颜色阈值配置)）
3. 改善光照条件：
   - 增加光照强度
   - 使用均匀光照，避免阴影
   - 避免强光直射导致过曝

**问题**：检测到背景或其他物体

**解决方法**：
1. 收紧颜色阈值范围：
   - 增大S（饱和度）的最小值
   - 增大V（明度）的最小值
   - 缩小H（色相）的范围
2. 改善背景：
   - 使用与物体颜色对比明显的背景
   - 避免背景中有相似颜色的物体

#### 2. 位置精度调优

**问题**：X/Y方向位置偏差

**调优步骤**：
1. 运行系统，检测物体并保存坐标
2. 控制机器人移动到保存的坐标
3. 观察实际抓取位置与目标位置的偏差
4. 计算偏差量：
   - 如果实际位置在X方向偏右10mm，设置 `X_OFFSET = -10.0`
   - 如果实际位置在X方向偏左10mm，设置 `X_OFFSET = 10.0`
   - Y方向同理
5. 重新测试，逐步调整到最佳值

**问题**：Z方向位置偏差

**调优步骤**：
1. 检查 `TOOL_LENGTH` 是否正确
2. 调整 `Z_OFFSET`（最终目标位置）：
   - 如果抓取时碰撞物体：减小绝对值（如从-10改为-5）
   - 如果抓取不到物体：增大绝对值（如从-10改为-20）
3. 调整 `HOVER_HEIGHT`（悬停高度）：
   - 如果悬停位置过高导致无法到达：减小此值（如从50改为30）
   - 如果需要更高的安全性：增大此值（如从50改为80）
   - 确保悬停位置在机器人工作空间内
4. 多次测试，找到最佳Z_OFFSET和HOVER_HEIGHT值

#### 3. 姿态精度调优

**问题**：抓取姿态不正确

**如果使用法向量估算**：
1. 检查 `ENABLE_NORMAL_ESTIMATION` 是否为True
2. 调整 `NORMAL_NEIGHBORHOOD_SIZE`：
   - 如果表面不平整：增大此值（如20-30）
   - 如果对边缘敏感：减小此值（如10）
3. 调整 `DEPTH_FILTER_THRESHOLD`：
   - 如果表面不平整：增大此值（如0.02-0.03）
   - 如果表面很平整：减小此值（如0.005）

**如果使用固定姿态**：
1. 检查 `ROBOT_INITIAL_POSE` 中的姿态角度（rx, ry, rz）
2. 根据抓取需求调整角度
3. 如果物体是正方体，通常垂直抓取即可（rx=-180, ry=0, rz=90）

#### 4. 标定质量检查

**问题**：整体精度不高

**可能原因**：
1. 标定质量不好
2. 标定文件选择不当

**解决方法**：
1. 检查标定误差：
   - 查看标定时的重投影误差
   - 误差应该小于1mm
2. 尝试不同的标定算法：
   - 比较Tsai、Park、Horaud三种算法的误差
   - 选择误差最小的算法对应的标定文件
3. 重新标定（如果误差太大）：
   - 使用更多位姿（建议15组以上）
   - 确保标定板清晰可见
   - 避免反光和遮挡

### 调优检查清单

在开始实际抓取任务前，确认以下项目：

- [ ] 机器人IP地址正确
- [ ] 标定文件已加载且误差合理
- [ ] 机器人初始位姿正确
- [ ] 工具长度正确
- [ ] 颜色检测稳定可靠
- [ ] X/Y位置精度满足要求（偏差<5mm）
- [ ] Z位置精度满足要求（能正确抓取）
- [ ] HOVER_HEIGHT设置合理（悬停位置在工作空间内）
- [ ] 两阶段运动正常执行（先悬停再下降）
- [ ] 姿态角度正确（如果需要）
- [ ] 机器人移动安全无碰撞

---

## 故障排除

### 常见问题及解决方法

#### 1. 无法连接机器人

**症状**：程序启动时报错，提示无法连接机器人

**可能原因**：
- 机器人IP地址错误
- 网络不通
- 机器人未上电或未处于可控制状态

**解决方法**：
1. 检查 `src/config/robot_config.py` 中的 `DEFAULT_ROBOT_IP`
2. 使用ping命令测试网络连通性：
   ```bash
   ping 192.168.2.68
   ```
3. 检查机器人状态：
   - 确认机器人已上电
   - 确认机器人处于可控制状态（非急停状态）
   - 确认机器人RPC服务已启动

#### 2. 无法加载标定文件

**症状**：程序启动时报错，提示无法加载标定文件

**可能原因**：
- 标定文件路径错误
- 标定文件不存在
- 标定文件格式错误

**解决方法**：
1. 检查 `src/config/detection_config.py` 中的 `CALIB_FILE` 路径
2. 确认标定文件存在于 `calibration/` 目录下
3. 如果标定文件不存在，需要先进行手眼标定（参考 `手眼标定使用指南.md`）

#### 3. 相机无法初始化

**症状**：程序启动时报错，提示相机初始化失败

**可能原因**：
- 相机未连接
- 相机驱动未安装
- USB接口问题
- 其他程序占用相机

**解决方法**：
1. 检查相机USB连接：
   - 确认USB线已连接
   - 尝试更换USB接口（建议使用USB 3.0）
   - 确认USB线支持数据传输（非仅充电线）
2. 检查相机驱动：
   ```bash
   python -c "import pyrealsense2 as rs; print('驱动正常')"
   ```
   如果报错，重新安装pyrealsense2：
   ```bash
   pip uninstall pyrealsense2
   pip install pyrealsense2
   ```
3. 关闭其他可能占用相机的程序（如RealSense Viewer）

#### 4. 检测不到物体

**症状**：相机画面正常，但检测不到物体

**可能原因**：
- 颜色阈值配置不正确
- 光照条件不合适
- 物体不在视野内
- 物体颜色不在COLOR_RANGES中

**解决方法**：
1. 检查物体颜色是否在 `COLOR_RANGES` 中配置
2. 使用OpenCV颜色选择器工具调整阈值（参考[参数调优指南](#参数调优指南)）
3. 改善光照条件：
   - 增加光照强度
   - 使用均匀光照
   - 避免强光直射
4. 确认物体在相机视野内且清晰可见
5. 检查背景是否与物体颜色对比明显

#### 5. 检测位置不准确

**症状**：能检测到物体，但计算的位置与实际位置偏差较大

**可能原因**：
- 标定质量不好
- TOOL_LENGTH不正确
- X_OFFSET/Y_OFFSET需要调整
- 深度信息不准确

**解决方法**：
1. 检查标定质量：
   - 查看标定时的重投影误差
   - 如果误差>1mm，考虑重新标定
2. 检查TOOL_LENGTH：
   - 测量实际工具长度
   - 确认配置值与实际值一致
3. 调整X_OFFSET和Y_OFFSET（参考[参数调优指南](#参数调优指南)）
4. 检查深度信息：
   - 确认物体表面能反射红外光（RealSense使用结构光）
   - 避免透明、反光或黑色表面
   - 确保物体距离相机在有效范围内（通常0.3-3米）

#### 6. 机器人移动失败

**症状**：按W键后，机器人不移动或移动失败

**可能原因**：
- 机器人不在可控制状态
- 目标位姿超出工作空间
- **悬停位置超出工作空间**（两阶段运动第一阶段）
- 机器人运动被限制
- 网络延迟或丢包

**解决方法**：
1. 检查机器人状态：
   - 确认机器人处于可控制状态
   - 确认没有急停或安全限制
2. 检查目标位姿：
   - 查看控制台输出的目标位姿
   - 确认位姿在机器人工作空间内
   - 如果超出范围，调整ROBOT_INITIAL_POSE或物体位置
3. **检查悬停位置**（两阶段运动）：
   - 悬停位置z = 目标z + HOVER_HEIGHT
   - 如果第一阶段失败，检查悬停位置是否在工作空间内
   - 如果悬停位置过高，减小HOVER_HEIGHT值（如从50改为30）
   - 查看控制台输出的第一阶段错误信息
4. 检查网络连接：
   - 确认网络稳定
   - 如果网络延迟大，可能需要等待更长时间
5. 查看错误信息：
   - 控制台会显示错误码和阶段信息（第一阶段/第二阶段）
   - 如果第一阶段失败，重点检查HOVER_HEIGHT设置
   - 如果第二阶段失败，重点检查目标位姿
   - 根据错误码查阅机器人文档

#### 7. 深度信息无效

**症状**：检测到物体中心，但提示"深度无效"

**可能原因**：
- 物体表面无法反射红外光（透明、反光、黑色）
- 物体距离相机太近或太远
- 深度滤波器过滤掉了有效点

**解决方法**：
1. 检查物体表面材质：
   - 避免透明物体（玻璃、透明塑料）
   - 避免强反光表面（镜面、金属）
   - 避免纯黑色表面（吸收红外光）
2. 调整物体位置：
   - 确保物体距离相机在有效范围内（0.3-3米）
   - 避免物体太靠近相机边缘
3. 调整深度滤波参数（如果问题持续）：
   - 减小 `DEPTH_FILTER_THRESHOLD`
   - 减小 `MIN_POINTS_FOR_NORMAL`

#### 8. 程序运行卡顿

**症状**：程序运行缓慢，画面卡顿

**可能原因**：
- 计算机性能不足
- 法向量估算计算量大
- 其他程序占用资源

**解决方法**：
1. 关闭法向量估算（如果不需要）：
   ```python
   ENABLE_NORMAL_ESTIMATION = False
   ```
2. 关闭其他占用资源的程序
3. 降低相机分辨率（修改 `realsense_camera.py` 中的分辨率设置）

### 获取帮助

如果以上方法无法解决问题，请：

1. **收集错误信息**：
   - 记录完整的错误信息
   - 截图显示问题的画面
   - 记录操作步骤

2. **检查日志**：
   - 查看控制台输出的所有信息
   - 记录关键错误信息

3. **联系支持**：
   - 提交Issue，附上错误信息和截图
   - 或联系项目维护者

---

## 注意事项

### 安全注意事项

1. **首次使用前**：
   - 确保机器人工作空间内没有人员
   - 确认机器人急停按钮可用
   - 建议先手动控制机器人移动到初始位姿，确认安全

2. **运行过程中**：
   - 随时准备按 **Z** 键停止机器人
   - 不要将手或其他物体伸入机器人工作空间
   - 注意观察机器人移动轨迹，避免碰撞

3. **参数调整**：
   - 首次使用时，建议使用较小的Z_OFFSET值（如-10mm）进行测试
   - 逐步调整参数，避免突然的大幅移动

### 标定注意事项

1. **标定质量**：
   - 标定质量直接影响检测精度
   - 建议使用至少15组不同位姿的标定数据
   - 标定板应清晰可见，避免反光和遮挡

2. **标定一致性**：
   - `ROBOT_INITIAL_POSE` 必须与标定时的拍照位姿一致
   - 如果修改了初始位姿，可能需要重新标定

3. **标定文件选择**：
   - 比较不同算法的标定误差
   - 选择误差最小的算法对应的标定文件

### 相机使用注意事项

1. **安装固定**：
   - 确保相机固定安装，避免振动
   - 相机与机器人法兰的相对位置必须与标定时一致

2. **环境要求**：
   - 保持相机镜头清洁
   - 避免强光直射镜头
   - 确保工作区域光照充足且均匀

3. **深度信息**：
   - 避免检测透明、反光或纯黑色物体
   - 确保物体距离相机在有效范围内

### 性能优化建议

1. **计算性能**：
   - 如果不需要法向量估算，关闭 `ENABLE_NORMAL_ESTIMATION`
   - 关闭不必要的平滑滤波

2. **检测稳定性**：
   - 使用合适的颜色阈值，避免误检
   - 确保光照条件稳定

3. **机器人控制**：
   - 机器人移动使用后台线程，不会阻塞检测
   - 可以连续检测多个物体，逐个保存和移动

### 维护建议

1. **定期检查**：
   - 定期检查标定精度（建议每月一次）
   - 检查相机镜头是否清洁
   - 检查机器人工具长度是否有变化

2. **备份配置**：
   - 备份标定文件
   - 备份配置文件
   - 记录参数调整历史

3. **更新日志**：
   - 记录每次参数调整的原因和效果
   - 记录遇到的问题和解决方法

---

## 附录

### 快捷键总结

| 按键 | 功能 | 使用场景 |
|------|------|----------|
| **Q** | 暂停/恢复检测 | 暂停时会自动保存检测坐标 |
| **W** | 两阶段移动到保存的坐标 | 必须在暂停状态下使用，先悬停再下降 |
| **B** | 回到初始位姿 | 全局快捷键，随时可用 |
| **Z** | 停止机器人移动 | 全局快捷键，紧急停止，可在两阶段运动任一阶段停止 |
| **R** | 显示提示信息 | 查看平滑处理状态 |
| **ESC** | 退出程序 | 安全退出 |

### 配置文件快速参考

**机器人配置** (`src/config/robot_config.py`)：
- `DEFAULT_ROBOT_IP`：机器人IP地址
- `DEFAULT_ROBOT_TOOL`：工具号
- `DEFAULT_ROBOT_USER`：用户坐标系号

**检测配置** (`src/config/detection_config.py`)：
- `CALIB_FILE`：标定文件路径
- `ROBOT_INITIAL_POSE`：机器人初始位姿
- `TOOL_LENGTH`：工具长度
- `Z_OFFSET`：Z轴偏移量（最终目标位置）
- `HOVER_HEIGHT`：悬浮高度（两阶段运动第一阶段）
- `X_OFFSET`、`Y_OFFSET`：X/Y轴偏移补偿
- `COLOR_RANGES`：颜色阈值配置
- `ENABLE_NORMAL_ESTIMATION`：是否启用法向量估算

### 坐标系说明

本项目涉及多个坐标系：

1. **相机坐标系**：以相机光心为原点，Z轴沿光轴方向
2. **夹爪坐标系**：以夹爪中心为原点
3. **基坐标系**：以机器人基座为原点
4. **工具坐标系**：以TCP（工具中心点）为原点

坐标转换流程：
```
像素坐标 → 相机坐标 → 夹爪坐标 → 基坐标 → TCP坐标
```

### 相关文档

- `README.md`：项目总体说明
- `手眼标定使用指南.md`：手眼标定详细教程
- `src/`：源代码目录，包含各模块实现

---

**文档版本**：v1.1  
**最后更新**：2026-01-28  
**维护者**：项目开发团队

**更新日志**：
- v1.1 (2026-01-28)：新增两阶段运动功能说明，添加HOVER_HEIGHT参数配置说明
- v1.0 (2026-01-27)：初始版本

如有问题或建议，请提交Issue或联系项目维护者。
